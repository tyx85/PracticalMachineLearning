submit()
submit()
cran %>% select (ip_id, country, package, size) %>% print
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res <- gather(students2, sex_class, count)
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(res, sex_class, c("sex","class"))
submit()
students3
submit()
?spread()
?spread
submit()
submit()
submit()
submit()
submit()
extract_numeric("class5")
submit()
submit()
submit()
students4
submit()
submit()
?unique
submit()
submit()
passed
failed
passed <- mutate(passed, status = "passed")
failed <- mutate(failed, status = "failed")
?rbind_list
rbind_list(passed, failed)
sat
?select
submit()
submit()
?separate
submit()
submit()
submit()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
hour(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("//192012")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms(03:22:14)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes =34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = 8, minutes =34, seconds = 55)
this_moment
?now
nyc <- now(tzone = "America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- depart+hours(15)+minutes(50)
?with_tz
arrive <- with_tz(arrive, "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008","Singapore")
last_time <- mdy("June 17, 2008", tz="Singapore")
last_time
?new_interbal()
?new_interval()
?new_interval
how_long <- new_interval(last_time, arrive)
as.period(how_long)
stopwatch()
bye()
bye()
quit()
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "eb16f1a9c7b1352a0408")
myapp <- oauth_app("github", "eb16f1a9c7b1352a0408","52bc869a8c30aa92e7241b71298f97c419859446")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
req <- with_config(gtoken, GET("https://api.github.com/rate_limit"))
content(req)
stop_for_status(req)
req
content(req)
json1 = content(req)
bye()
quit()
?cumsun
?cumsum
value2<- 70
mean2<- 80
sd2<- 10
answ2<-pnorm(value2, mean2, sd2)
round(answ2, 2)
quantil3<- 0.95
mean3<- 1100
sd3<- 75
answ3<-qnorm(quantil3, mean3, sd3)
round(answ3,0)
mean6<- 15
sd6<- 10
value6a<- (14-mean6)/(sd6/sqrt(100))
p14<-pnorm(value6a)
value6b<- (16-mean6)/(sd6/sqrt(100))
p16<-pnorm(value6b)
answ6<-p16-p14
round(answ6,2)
qt(.95,8)
sp<-sqrt((2*0.60^2+4*0.60^2)/(3+5-2))
library(swirl)
install_from_swirl("Statistical Inference")
swirl()
11/12
deck
52
4/52
0
3/13
2/51
.64
.64
mypdf
integrate(mypdf,0,1.6)
1.414214
.997*.001
(1-.985)*(1-.001)
equiv_val(.06238268)
equiv_val(.06238268)
.000997/(.000997+.014985)
3.5
expect_dice
dice_high
expect_dice(dice_high)
expect_dice(dice_low)
3.5
integrate(myfunc,0,2)
spop
mean(spop)
allsam
apply(allsam,1,mean)
mean(smeans)
dice_sqr
ex2_fair <- sum(dice_fair * dice_sqr)
ex2_fair-3.5^2
sum(dice_high * dice_sqr)-edh^2
sd(apply(matrix(rnorm(10000),1000),1,mean))
1/sqrt(10)
1/sqrt(12*n)
1/sqrt(120)
sd(apply(matrix(runif(10000),1000),1,mean))
sd(apply(matrix(rpois(10000,4),1000),1,mean))
2/sqrt(10)
sd(apply(matrix(rpois(10000,4),1000),1,mean))
1/(2*sqrt(10))
sd(apply(matrix(sample(0:1,10000,TRUE),1000),1,mean))
quit
bye
exit
exit()
quit()
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit<-lm(y~x)
summary(fit)
x<-mtcars$wt
y<-mtcars$mpg
predict(lm(y~x) , newdata = data.frame(x=mean(x)), interval="confidence")
?mtcars
predict(fit,data.frame(x=3),interval=("prediction"))
x<-mtcars$wt*0.5
fit<-lm(y~x)
#predict(fit,data.frame(x=3),interval=("confidence"))
sumCoef<-summary(fit)$coefficients
sumCoef[2,1]+c(-1,1)*qt(.975,df=fit$df)*sumCoef[2,2]
summary(fit)
fit[[1]][1] + 3 * fit[[1]][2]
attributes(fit)
w.c <- fit$residuals ^ 2
fit.c <- lm(mpg ~ 1, mtcars)
fit.c.res <- fit.c$residuals ^ 2
sum(fit.c.res)
sum(w.c) /sum(fit.c.res)
data(mtcars)
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit2 <- lm(mpg ~ factor(cyl) + wt + interaction(cyl, wt), data = mtcars)
# To compare model we usually use an anova table
# anova null hypothesis says that both models are the same.
compare <- anova(fit1, fit2)
compare$Pr
fit3 <- lm(mpg ~ factor(cyl)*wt, mtcars)
summary(fit3)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
# Give the hat diagonal for the most influential point
fit <- lm(y ~ x)
hatvalues(fit)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit <- lm(y ~ x)
lm.influence(fit)$hat
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
# Give the slope dfbeta for the point with the highest hat value.
fit <- lm(y ~ x)
dfbetas(fit)
library(knitr)
data(mtcars)
mtcars$cyl <- factor(mtcars$cyl)
mtcars$vs <- factor(mtcars$vs)
mtcars$am <- factor(mtcars$am, labels = c("Automatic", "Manual"))
mtcars$gear <- factor(mtcars$gear)
mtcars$carb <- factor(mtcars$carb)
everything_model = lm(mpg ~ ., data = mtcars)
boxplot(mpg ~ am, data = mtcars,
xlab = "Transmission type", ylab = "Miles per gallon",
main = "MPG vs Transmission", col = c("salmon", "steelblue"),
names = c("Automatic", "Manual"))
p1 = pairs(mtcars, panel = panel.smooth, main = "Pairwise plot of mtcars data")
fit1 <- lm(mpg ~ am, data = mtcars)
fit1
everything_model = lm(mpg ~ ., data = mtcars)
everything_model$coeff
head(cov2cor(cov(sapply(mtcars, as.numeric))), 1)
everything_model = lm(mpg ~ ., data = mtcars)
everything_model$coeff
everything_model
fit1 <- lm(mpg ~ am, data = mtcars)
fit1
xlab = "Transmission type", ylab = "Miles per gallon",
library(knitr)
data(mtcars)
mtcars$cyl <- factor(mtcars$cyl)
mtcars$vs <- factor(mtcars$vs)
mtcars$am <- factor(mtcars$am, labels = c("Automatic", "Manual"))
mtcars$gear <- factor(mtcars$gear)
mtcars$carb <- factor(mtcars$carb)
init_fit = lm(mpg ~ ., data = mtcars)
best_fit = step(init_fit, direction = "both")
summary(best_fit)
simple_fit <- lm(mpg ~ am, data = mtcars)
anova(simple_fit,best_fit,init_fit)
leverage <- hatvalues(best_fit)
tail(sort(leverage),3)
influential <- dfbetas(best_fit)
tail(sort(influential[,6]),3)
t.test(mpg ~ am, data = mtcars)
boxplot(mpg ~ am, data = mtcars,
xlab = "Transmission type", ylab = "Miles per gallon",
main = "MPG vs Transmission", col = c("salmon", "steelblue"),
names = c("Automatic", "Manual"))
p1 = pairs(mtcars, panel = panel.smooth, main = "Pairwise plot of mtcars data")
head(cov2cor(cov(sapply(mtcars, as.numeric))), 1)
init_fit_model = lm(mpg ~ ., data = mtcars)
init_fit_model$coeff
qqnorm(simple_fit$residual,
main="Normal Q-Q",
xlab="Theoretical Quantiles",
ylab="Standardized residuals")
plot(simple_fit$fitted.values, simple_fit$residual,
ylab="Residuals", xlab="Fitted values",
main="Residuals vs Fitted")
plot(simple_fit$residual, simple_fit$fitted.values,
ylab="Residuals", xlab="Fitted values",
main="Residuals vs Fitted")
plot(best_fit$fitted.values, best_fit$residual,
ylab="Residuals", xlab="Fitted values",
main="Residuals vs Fitted")
qqnorm(best_fit$residual,
main="Normal Q-Q",
xlab="Theoretical Quantiles",
ylab="Standardized residuals")
library(MASS)
data(shuttle)
# convert outcome to 0 = noauto, 1 = auto
shuttle$use <- factor(shuttle$use, levels = c("auto", "noauto"), labels = c(1, 0))
fit1 <- glm(use ~ wind - 1, data = shuttle, family = "binomial")
summary(fit)
windhead <- fit1$coef[1]
windtail <- fit1$coef[2]
exp(windtail)/exp(windhead)
library(MASS)
data(shuttle)
# convert outcome to 0 = noauto, 1 = auto
shuttle$use <- factor(shuttle$use, levels = c("auto", "noauto"), labels = c(1, 0))
# Question 2
# Consider the previous problem. Give the estimated odds ratio for autoloader
# use comparing head winds (numerator) to tail winds (denominator) adjusting for
# wind strength from the variable magn.
fit2 <- glm(use ~ wind + magn - 1, data = shuttle, family = "binomial")
summary(fit)
windhead2 <- fit2$coef[1]
windtail2 <- fit2$coef[2]
exp(windtail2)/exp(windhead2)
library(MASS)
data(shuttle)
shuttle$auto <- as.numeric(shuttle$use=="auto")
fit <- glm(auto ~ wind,  binomial,  shuttle)
fit3 <- glm(1-auto ~ wind,  binomial, shuttle)
fit$coefficients
fit3$coefficients
data(InsectSprays)
fit <- glm(count ~ spray  - 1, family = "poisson", data = InsectSprays)
exp(fit$coef[1])/exp(fit$coef[2])
data(mtcars)
fit1 <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit1
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
# lin.mod <- lm(y ~ x)
# segmented.mod <- segmented(lin.mod, seg.Z = ~ x, psi = 0)
#
# summary(segmented.mod)
#
# plot(x, y)
# plot(segmented.mod, add = TRUE)
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
lhs <- function(x) ifelse(x < 0,0-x,0) # basis function 1 (lhs = left hockey stick)
rhs <- function(x) ifelse(x > 0,x-0,0) # basis function 2 (rhs = right hockey stick)
gb <- lm(y ~ lhs(x) + rhs(x))
x <- seq(-5,5,by=1)
py <- gb$coef[1]+gb$coef[2]*lhs(x)+gb$coef[3]*rhs(x)
lines(x, py)
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
lhs <- function(x) ifelse(x < 0,0-x,0) # basis function 1 (lhs = left hockey stick)
rhs <- function(x) ifelse(x > 0,x-0,0) # basis function 2 (rhs = right hockey stick)
gb <- lm(y ~ lhs(x) + rhs(x))
x <- seq(-5,5,by=1)
py <- gb$coef[1]+gb$coef[2]*lhs(x)+gb$coef[3]*rhs(x)
lines(x, py)
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
# lin.mod <- lm(y ~ x)
# segmented.mod <- segmented(lin.mod, seg.Z = ~ x, psi = 0)
#
# summary(segmented.mod)
#
plot(x, y)
plot(segmented.mod, add = TRUE)
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
lhs <- function(x) ifelse(x < 0,0-x,0) # basis function 1 (lhs = left hockey stick)
rhs <- function(x) ifelse(x > 0,x-0,0) # basis function 2 (rhs = right hockey stick)
gb <- lm(y ~ lhs(x) + rhs(x))
x <- seq(-5,5,by=1)
py <- gb$coef[1]+gb$coef[2]*lhs(x)+gb$coef[3]*rhs(x)
lines(x, py)
py
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
install.package("caret")
install.packages("caret")
install.packages("rpart/plot")
install.packages("rpart.plot")
install.packages("randomForest")
install.packages("corrplot")
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
getwd()
setwd("/Users/thamyongxiang/MOOC")
dir
dir()
setwd("/Users/thamyongxiang/MOOC/Practical Machine Learning")
dir()
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
## Putting the data files into data folder so it will appear more organize
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
download.file(trainUrl, destfile=trainFile, method="curl")
download.file(testUrl, destfile=testFile, method="curl")
trainFile <- "pml-training.csv"
testFile  <- "pml-testing.csv"
download.file(trainUrl, destfile=trainFile, method="curl")
download.file(testUrl, destfile=testFile, method="curl")
trainData <- read.csv("pml-training.csv")
testData <- read.csv("pml-testing.csv")
dim(trainData)
dim(testData)
sum(complete.cases(trainData))
trainData <- trainData[, colSums(is.na(trainData)) == 0]
testData <- testData[, colSums(is.na(testData)) == 0]
classe <- trainData$classe
trainColRemove <- grepl("^X|timestamp|window", names(trainData))
trainData <- trainData[, !trainColRemove]
trainCleaned <- trainData[, sapply(trainData, is.numeric)]
trainCleaned$classe <- classe
testColRemove <- grepl("^X|timestamp|window", names(testData))
testData <- testData[, !testColRemove]
testCleaned <- testData[, sapply(testData, is.numeric)]
dim(trainCleaned)
dim(testCleaned)
set.seed(12345) # For reproducibile purpose
splitData <- createDataPartition(trainCleaned$classe, p=0.70, list=F)
trainNewData <- trainCleaned[splitData, ]
testNewData <- trainCleaned[-splitData, ]
crossValidation <- trainControl(method="cv", 5)
modelling <- train(classe ~ ., data=trainNewData, method="rf", cValid=crossValidation, ntree=250)
modelling
modelling <- train(classe ~ ., data=trainNewData, method="rf", cValid=crossValidation, ntree=250)
install.packages('e1071', dependencies=TRUE)
modelling <- train(classe ~ ., data=trainNewData, method="rf", cValid=crossValidation, ntree=250)
modelling <- train(classe ~ ., data=trainNewData, method="rf", cValid=crossValidation, ntree=250)
set.seed(22519) # For reproducibile purpose
splitData <- createDataPartition(trainCleaned$classe, p=0.70, list=F)
trainNewData <- trainCleaned[splitData, ]
testNewData <- trainCleaned[-splitData, ]
crossValidation <- trainControl(method="cv", 5)
modelling <- train(classe ~ ., data=trainNewData, method="rf", cValid=crossValidation, ntree=250)
modelling <- train(classe ~ ., data=trainNewData, method="rf", cValid=crossValidation)
modelling <- train(classe ~ ., data=trainNewData, method="rf", trControl=crossValidation, ntree=250)
modelling <- train(classe ~ ., data=trainNewData, method="rf", trControl=crossValidation)
crossValidation <- trainControl(method="cv")
modelling <- train(classe ~ ., data=trainNewData, method="rf", trControl=crossValidation)
modelling <- train(classe ~ ., data=trainNewData, method="rf", trControl=crossValidation, ntree=150)
registerDoParallel()
x <- trainNewData[-ncol(trainNewData)]
y <- trainNewData$classe
rf <- foreach(ntree=rep(150, 6), .combine=randomForest::combine, .packages='randomForest') %dopar% {
randomForest(x, y, ntree=ntree)
}
library(foreach)
library(doParallel)
install.packages("doParallel")
registerDoParallel()
x <- trainNewData[-ncol(trainNewData)]
y <- trainNewData$classe
rf <- foreach(ntree=rep(150, 6), .combine=randomForest::combine, .packages='randomForest') %dopar% {
randomForest(x, y, ntree=ntree)
}
library(doParallel)
registerDoParallel()
x <- trainNewData[-ncol(trainNewData)]
y <- trainNewData$classe
rf <- foreach(ntree=rep(150, 6), .combine=randomForest::combine, .packages='randomForest') %dopar% {
randomForest(x, y, ntree=ntree)
}
predictions1 <- predict(rf, newdata=trainNewData)
confusionMatrix(predictions1,trainNewData$classe)
predictions1 <- predict(rf, newdata=testNewData)
confusionMatrix(predictions1,testNewData$classe)
predictiveModelling <- foreach(ntree=rep(150, 6), .combine=randomForest::combine, .packages='randomForest') %dopar% {
randomForest(x, y, ntree=ntree)
}
predictionsTrain <- predict(predictiveModelling, newdata=trainNewData)
confusionMatrix(predictionsTrain,trainNewData$classe)
predictionsTest <- predict(predictiveModelling, newdata=testNewData)
confusionMatrix(predictionsTest,testNewData$classe)
ml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
x <- evaluation_data
x <- x[feature_set[feature_set!='classe']]
answers <- predict(predictiveModelling, newdata=x)
answers
pml_write_files(answers)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
answers <- predict(predictiveModelling, newdata=testCleaned)
answers
pml_write_files(answers)
